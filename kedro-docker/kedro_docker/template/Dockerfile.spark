ARG BASE_IMAGE=python:3.9-slim
FROM $BASE_IMAGE as runtime-environment

# install JVM
RUN apt-get update && mkdir -p /usr/share/man/man1 && \
    apt-get install -y procps default-jre-headless && rm -rf /var/lib/apt/lists/*

# update pip and install uv
RUN python -m pip install -U "pip>=21.2"
RUN pip install uv

# install project requirements
COPY requirements.txt /tmp/requirements.txt
RUN uv pip install --system --no-cache-dir -r /tmp/requirements.txt && rm -f /tmp/requirements.txt

# add kedro user
ARG KEDRO_UID=999
ARG KEDRO_GID=0
RUN groupadd -f -g ${KEDRO_GID} kedro_group && \
    useradd -m -d /home/kedro_docker -s /bin/bash -g ${KEDRO_GID} -u ${KEDRO_UID} kedro_docker

WORKDIR /home/kedro_docker
USER kedro_docker

FROM runtime-environment
# copy the whole project except what is in .dockerignore
ARG KEDRO_UID=999
ARG KEDRO_GID=0
COPY --chown=${KEDRO_UID}:${KEDRO_GID} . .

# Create startup script that configures Spark properly
RUN echo '#!/bin/bash\n\
export JAVA_OPTS="--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED"\n\
export PYSPARK_SUBMIT_ARGS="--driver-java-options=\"--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED\" --executor-java-options=\"--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED\" pyspark-shell"\n\
exec kedro run\n\
' > /home/kedro_docker/run_kedro.sh && \
chmod +x /home/kedro_docker/run_kedro.sh

EXPOSE 8888

CMD ["/home/kedro_docker/run_kedro.sh"]
